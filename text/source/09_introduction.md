# Увод

## Мотивация

Последните години донесоха бързо развитие на изкуствения интелект и по-конкретно на дълбокото самообучение (Deep Learning). Моделите, използващи тези методи, имат разнообразни приложения и понякога се представят сходно или по-добре от човек, решаващ същата задача. Областите, в които успешно са използвани системи с изкуствен интелект са:

- здравеопазване [@rajkomar2018scalable], [@poplin2018prediction], [@lee2017deep]
- самоуправляващи се автомобили [@bojarski2016end], [@huval2015empirical], [@bojarski2017explaining]
- търгуване на стоковата борса
- създаване на изкуство

Една от основните цели на изкуствения интелект (ИИ) е да създаде агенти, които разбират и взаимодействат със света около нас. Значителен прогрес в тази насока беше постигнат през последните години благодарение на развитието на изчислителната техника (графични ускорители), наличието на голямо количество данни, нови начини за събиране и съхранението им, нов математически апарат и нови алгоритми. Бързият напредък в сферата на подсиленото обучение доведе до разработката на интелигентни агенти, взаимодействащи с все по-сложни среди [@mnih2015human], [@silver2016alphago], [@levine2016end] и [@silver2017mastering]. От особена важност за това са обучаващите алгоритми, техники за скалирането им и симулационни среди, които предоставят начини за оценка и сравняване на различни агенти [@bellemare2013arcade], [@todorov2012mujoco] и [@johansson2016learning].

Хората се справят лесно с редица задачи, които изискват комплексно разбиране на визуалния свят, разпознаване на различни обекти в него и взаимодействие с тях. Например екран от ГПИ среда и разпознаване на обекти в него. Би било лесно за човек да изучи подобна визуална среда.

Агенти, действащи в симулирани среди, са фундаментално ограничени - те никога не се сблъскват със сложността на реалния свят, поради което не могат да използват семантично знание и достигнат интелигентност. В роботиката агентите действат в реална среда, но процесът на обучение е бавен и скъп, дори и за тясно дефинирани задачи [@levine2016end].

За справянето с тези проблеми могат да се използват среди, базирани на ГПИ приложения [@pmlr-v70-shi17a]. Те предоставят разнообразни задачи, възможност за бързо итериране и обучение. Агентите получават същите сензорни данни, които получава човек, взаимодействащ с тези среди. Те предоставят възможност за изграждане на знание, невъзможно за придобиване в симулации.

**Предизвикателства** Тъй като подобни възможности изглеждат естествени за човек, може да забравим колко трудни са те за един агент. Изображенията са представени като голям масив от числа, които представят яркостта за всяка позиция. Едно такова изображение може да съдържа милиони такива *пиксели*, които агентът трябва да трансформира до семантични концепции на високо ниво, като например "текст" или "бутон". При това, различни форми и цветове на даден бутон, също трябва да се класифицират като такъв, независимо от възможността за наличие на напълно различни шаблони (patterns) в яркостта на пикселите.

Концептуалното разбиране на дадено изображение е само първата стъпка за създаването на подобни агенти. Основна задача е създаване на модел на агент, който избира действия, които до доведат да постигането на поставена задача. Трудността тук се изразява в липсата на пълна информация (fully observed) за средата в която агента действа. Например, натискането на един и същи бутон в различни състояния на средата, може да доведе до наблюдаването на две напълно различни състояния на средата. Това означава, че е необходимо знание за конкретното състояние на средата.

Агентът няма предварителен модел на средата, която изучава. Той я "опознава", чрез опити и грешки, като се опитва да приложи различни комбинации от действия в дадено състояние, за да постигне оптимална награда. На всяка стъпка даден агент трябва да избере дали да използва вече наученото или да избере действие, което не е изпълнил в конкретното състояние. Тази дилема се нарича: компромис на изучаване и използване на наученото (exploration exploitation tradeoff) и е основна задача за решаване от всеки агент. ГПИ средите могат да предоставят голям брой действия за дадено състояние (например меню системата на Microsoft Word), което прави пълното им изучаване неприложимо в кратки интервали от време.

**Обнадеждаващ прогрес** Въпреки сложността на задачата, през последните години се наблюдава значителен прогрес в областта на подсиленото обучение. По конкретно, развитието на Изкуствените Невронни Мрежи (ИНМ) (Artificial Neural Networks) и методи за създаване на Бейсови модели с милиони параметри доведоха до значително разширение на областите в които подсиленото обучение е приложимо. Алгоритми като Дълбоко Q-обучение (Deep Q-learning) допринасят за създаване на агенти, които надхвърлят възможностите на хората в тясно дефинирани задачи [@mnih2015human], както и по-широко приложими такива [@silver2017mastering]

**Неотговорени въпроси** Основният подход, използван в много от тези приложения е създаване на модел, който работи в добре дефинирани среди или такива в които се наблюдава пълна информация. Допълнително, агентите взимат решения на базата на изчислени точкови оценки. Възможно е това да намаля ефективността на тези модели, както и обяснението на взетите решения. Открит остава въпросът дали добавянето на вероятностно разбиране за средата може да се справи с тези проблеми [@bellemare2017distributional] [@anonymous2018efficient].

**Принос** В тази работа добавяме вероятностно разбиране за средата и разработваме модели и техники за ефективно Бейсово изучаване на ГПИ среди. Също така създаваме конкретна среда, която Агентът изучава. Например, агентът трябва да наблюдава дадено изображение и избере действие, което максимизира вероятността за постигане на поставена цел. Този модел ще опише процесът за взимане на решения използвайки вероятностни разпределения. С други думи, целта на работата е създаване на агент, който ефективно изучава визуални среди.

**Дългосрочна мотивация** Основен стремеж на работата е да направи принос към изграждането и развитието на мислещи машини, както и приложи създадените модели в конкретни приложения. Техниките предложени тук са стъпка към достигането на бъдеще, в което агентите могат ефективно да взаимодействат с реалния свят (или по-сложни виртуални среди) и изпълняват комплексни задачи.

**Краткосрочна мотивация** Създаване на автоматизирани тестове за оценка на качеството на софтуерен продукт използвайки агент. Търсене за семантични и логически грешки в дадена програмна ГПИ среда. Възпроизвеждане на стъпки, необходими за възпроизвеждане на грешка.

Съществуващите методи не дават възможност за споделяне на наученото от друго приложение, намиране на аномалии във функционалността, бързо научаване на промени (премахване на старо знание) и оценка на несигурността при изпълнение на действие.

## Цели на дисертацията

Целта на дисертацията е да дефинира политика $\pi$, определяща поведението на агента.

- Дефиниране на множество от възможни действия на агента (пространтство на действията)
- Създаване на модел, който избира действията на агента
- Създаване на среда (за тестване и използване на агента) в която ще работи агента
  - Подбиране на приложения (applications)
  - Измерване на покритието на код
  - Създаване на изображение и сегментация от текущото състояние на средата
- Избор на метрики за оценка на действията на агента
- Да се построи модел за обучение на агента с учител. на агента с данни от хора, взаимодействащи със средата (imitation learning)
- Провеждане на експерименти
- Оценка и анализ на постигнатите резултати

Целта на настоящата дисертацаионна работа е да създаде система за автоматизирано тестване на ГПИ, която използва за входни данни само визуалния изход на тестваното приложение. За постигане на целта трябва да се изпълнят следните задачи:

- Избор на подходящи оценъчни функции и награди, които да мотивират максималното покритие на програмен код по време на тестване
- Създаване на структури, в които да се запазват поредиците от стъпки, необходими за повтаряне на тестови случай
- Създаване на модел, който генерира поредица от действия, използвани за играждане на тестовите случаи
- Създаване на модел, който намира аномалии по време на изпълнение на програмата
- Автоматично именуване на отделни екрани и действия с цел улесняване на разбирането
- Създаване и провеждане на експерименти, които да сравнят преложения модел с вече съществуващи такива
- По подадено изображение, йерархия на изгледите и действия, да се определи кои действия са валидни върху кои елементи


## Структура на дисертационния труд

**Глава 2** дава познания върху Дълбокото подсилено обучение и Бейсовото моделиране.  **Глава 3** поставя целите и задачите на текущата работа. В **Глава 4** се създава среда за тестване на Android мобилни приложения. **Глава 5** представя модел за генериране на входни данни за тестови случаи. В **Глава 6** се представя модел за намиране на аномалии в тестови случай по подадено изображение. Цялостната система е представена в **Глава 7** заедно с емпирични сравнения спрямо други решения. Нерешени проблеми, бъдещи подобрения и дискусия се намират в последната глава.

Обзор на литературните източници е направен в началото на глави **2**, **3** и **4**.


